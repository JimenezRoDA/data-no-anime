{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0508a2",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#33918d; font-weight: bold;\">An√°lisis de datos sobre la evoluci√≥n del anime</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc9818",
   "metadata": {},
   "source": [
    " <h2 style=\"color:#cc5064;font-weight: bold;\">Obtener los datos para el an√°lisis</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33cfafe",
   "metadata": {},
   "source": [
    " <h4 style=\"color:#cc5064;\">Primero las librerias y el data set a limpiar</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9239f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "df = pd.read_json('data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc1d8d",
   "metadata": {},
   "source": [
    " <h4 style=\"color:#33918d;\">Exploraci√≥n inicial y limpieza superficial</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ee6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df978b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f851dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef83b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No me deja ver los valores unicos de todas las columnas porque las columnas contienen listas.\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    if df[col].apply(lambda x: isinstance(x, list)).any():\n",
    "        print(f\"Columna {col} contiene listas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d5ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las listas de genres en columnas separadas\n",
    "# Primero, creamos una nueva DataFrame con las listas convertidas en series.\n",
    "genres_split = df['genres'].apply(lambda x: pd.Series(x) if isinstance(x, list) else pd.Series([None]*3))\n",
    "genres_split.columns = ['genre_1', 'genre_2', 'genre_3', 'genre_4', 'genre_5','genre_6','genre_7']\n",
    "\n",
    "# Concatenar las nuevas columnas al DataFrame original\n",
    "df_nuevo = pd.concat([df.drop(columns=['genres']), genres_split], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab376c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la proporci√≥n de valores nulos en las columnas de g√©neros para ver con cuales me quedo.\n",
    "proporcion_nulos = df_nuevo[['genre_1', 'genre_2', 'genre_3', 'genre_4', 'genre_5', 'genre_6', 'genre_7']].isna().sum() / df_nuevo.shape[0]\n",
    "print(proporcion_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ebe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo solo con las 2 primeras.\n",
    "df_nuevo = df_nuevo.drop(['genre_3', 'genre_4', 'genre_5', 'genre_6', 'genre_7'], axis=1)\n",
    "df = df_nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Me quedo solo con el primer theme.\n",
    "def extraer_theme_antes_coma(themes):\n",
    "    if isinstance(themes, list) and len(themes) > 0:\n",
    "        return themes[0].split(',')[0].strip()\n",
    "    return None\n",
    "\n",
    "df['themes'] = df['themes'].apply(extraer_theme_antes_coma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8db267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saco de la lista los titulos.\n",
    "df['titles'] = df['titles'].apply(lambda x: x[0] if isinstance(x, list) and x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6340487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al final themes no me ha parecido interesante.\n",
    "df.rename(columns={'popularity':'audicence_rank'}, inplace=True)\n",
    "df = df.drop(['favorites','themes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c35f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['mal_id', 'titles', 'type', 'genre_1', 'genre_2', 'source', 'studios', 'episodes', 'rating', 'score',\n",
    "       'audicence_rank','scored_by', 'rank', 'members', 'favorites',\n",
    "       'synopsis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora que tengo los datos un poco ordenados y se que me falta, voy a hacer web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e127b",
   "metadata": {},
   "source": [
    " <h2 style=\"color:#cc5064;font-weight: bold;\">Web Sraping</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_animes_top(limit=5550, step=50, delay=1):\n",
    "    animes = []\n",
    "\n",
    "    for offset in range(0, limit, step):\n",
    "        url = f\"https://myanimelist.net/topanime.php?limit={offset}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        lista = soup.find_all('tr', class_='ranking-list')\n",
    "\n",
    "        for anime in lista:\n",
    "            title_tag = anime.find('h3', class_='anime_ranking_h3')\n",
    "            title = title_tag.text.strip() if title_tag else None\n",
    "\n",
    "            info_div = anime.find('div', class_='information di-ib mt4')\n",
    "            fecha_emision = None\n",
    "            if info_div:\n",
    "                lines = info_div.text.strip().split('\\n')\n",
    "                if len(lines) >= 2:\n",
    "                    fecha_emision = lines[1].strip()\n",
    "\n",
    "            animes.append({\n",
    "                'title': title,\n",
    "                'fecha_emision': fecha_emision\n",
    "            })\n",
    "\n",
    "        time.sleep(delay)  # Pausa para evitar sobrecargar el servidor\n",
    "\n",
    "    return pd.DataFrame(animes)\n",
    "\n",
    "# Llamo a la funci√≥n\n",
    "df_fechas = obtener_animes_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo solo con el a√±o.\n",
    "df_fechas['year'] = df_fechas['fecha_emision'].str.extract(r'(\\d{4})').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le doy el mismo nombre que en el otro data frame para que funcione merge.\n",
    "df_fechas.rename(columns={'title': 'titles'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.merge(df,df_fechas,on='titles',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compruebo si me da una buena cantidad de animes despues de 2020.\n",
    "animes_2020_en_adelante = df_n[df_n['year'] >= 2020]\n",
    "print(f\"N√∫mero de animes desde 2020: {len(animes_2020_en_adelante)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c406f7e6",
   "metadata": {},
   "source": [
    " <h2 style=\"color:#cc5064;font-weight: bold;\">API</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48cc702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular_animes(limit=5550):\n",
    "    url = 'https://api.jikan.moe/v4/anime'\n",
    "    animes = []\n",
    "    page = 1\n",
    "    per_page = 25\n",
    "\n",
    "    while len(animes) < limit:\n",
    "        response = requests.get(url, params={'page': page, 'limit': per_page})\n",
    "        print(f\"P√°gina {page}, C√≥digo: {response.status_code}\")\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if not data.get('data'):\n",
    "                print(\"No hay m√°s datos.\")\n",
    "                break\n",
    "\n",
    "            animes.extend(data['data'])\n",
    "            print(f\"Total recolectado: {len(animes)}\")\n",
    "            page += 1\n",
    "            time.sleep(1)  # üõë Espera obligatoria para evitar rate limit\n",
    "        elif response.status_code == 429:\n",
    "            print(\"‚ö†Ô∏è Rate limit alcanzado. Esperando 10 segundos...\")\n",
    "            time.sleep(10)  # Espera m√°s larga para recuperarse\n",
    "        else:\n",
    "            print(f\"‚ùå Error en p√°gina {page}: {response.text}\")\n",
    "            break\n",
    "\n",
    "    return animes\n",
    "\n",
    "# Ejecutar funci√≥n para sacar informaci√≥n de la API\n",
    "popular_animes = get_popular_animes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_state = pd.DataFrame(popular_animes)\n",
    "df_state.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc782dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['mal_id', 'status', 'airing', 'season', 'year']\n",
    "df_2 = df_state[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8bfbcd",
   "metadata": {},
   "source": [
    " <h4 style=\"color:#33918d;\">Juntamos toda la informaci√≥n obtenida</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31059d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_n, df_2, on = 'mal_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40149b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['year'] = df_final['year_x'].combine_first(df_final['year_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630864ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(['year_x', 'year_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf12143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parece que tengo que filtrar los animes por a√±o para que me de animes m√°s nuevos, tendre que usar una funcion distinta para llamar a la api.\n",
    "animes_2020_en_adelante = df_final[df_final['year'] >= 2020]\n",
    "print(f\"N√∫mero de animes desde 2020: {len(animes_2020_en_adelante)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('anime_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7d2e2",
   "metadata": {},
   "source": [
    " <h4 style=\"color:#33918d;\">He pasado este df a un csv que esta en la misma carpeta, y que usare para hacer la limpieza y los insights. Hasta aqui la miner√≠a para conseguir la informacion que queria.</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
